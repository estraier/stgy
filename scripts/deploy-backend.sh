#!/usr/bin/env bash
set -euo pipefail

# ====== Embedded "production" config (baked into start.sh) ======
CFG_NODE_ENV=production
CFG_FRONTEND_ORIGIN=https://stgy.jp
CFG_BACKEND_PORT=3100
CFG_BACKEND_API_BASE_URL=http://127.0.0.1:3100
CFG_BACKEND_API_PRIVATE_URL_LIST=http://127.0.0.1:3100

# PostgreSQL (native service on the host)
CFG_DB_HOST=127.0.0.1
CFG_DB_PORT=5432
CFG_DB_USER=admin
CFG_DB_PASS=stgystgy
CFG_DB_NAME=stgy

# MinIO (host:9000 directly; public delivery via Caddy)
CFG_S3_ENDPOINT=http://127.0.0.1:9000
CFG_S3_REGION=us-east-1
CFG_S3_KEY=admin
CFG_S3_SECRET=stgystgy
CFG_S3_FORCE_PATH_STYLE=true
CFG_S3_BUCKET_PREFIX=stgy
CFG_S3_PUBLIC_URL_PREFIX=https://s3.stgy.jp/{bucket}/

# Redis (native service on the host)
CFG_REDIS_HOST=127.0.0.1
CFG_REDIS_PORT=6379
CFG_REDIS_PASS=stgystgy

# SMTP (Postfix on the same host; auth not required for localhost in your setup)
CFG_SMTP_HOST=127.0.0.1
CFG_SMTP_PORT=587
CFG_SMTP_USER=
CFG_SMTP_PASS=

# Misc
CFG_MAIL_FROM=noreply@stgy.jp
CFG_ID_WORKER=0
CFG_OPENAI_API_KEY="${STGY_OPENAI_API_KEY:-}"
CFG_TEST_SIGNUP_CODE=
# =======================================================================

REPO_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
OWNER="${DEPLOY_OWNER:-$(id -un)}"
GROUP="${DEPLOY_GROUP:-$(id -gn)}"
TARGET="${DEPLOY_TARGET:-$HOME/stgy-backend}"

echo "[backend] Building and staging artifacts..."
cd "$REPO_ROOT"

# Monorepo build (backend + shared package)
npm ci --workspaces --include-workspace-root
npm run packages:build
npm run backend:build
npm prune --omit=dev --workspaces --include-workspace-root

# Prepare target directory
mkdir -p "$TARGET"

# Install runtime assets
rsync -a --delete backend/dist/           "$TARGET/dist/"
rsync -a            backend/package.json  "$TARGET/backend.package.json"
rsync -a --delete node_modules/           "$TARGET/node_modules/"
rsync -a --delete packages/               "$TARGET/packages/"

# Sanity check for entrypoints
for f in index.js mailWorker.js mediaWorker.js notificationWorker.js aiSummaryWorker.js aiUserWorker.js ; do
  if [[ ! -f "$TARGET/dist/$f" ]]; then
    echo "[error] Missing '$TARGET/dist/$f' (did the backend build produce it?)"
    exit 1
  fi
done

# Generate start.sh (self-contained; baked config; supports start/stop/status/restart)
cat > "$TARGET/start.sh" <<'EOS'
#!/usr/bin/env bash
set -euo pipefail

APP_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$APP_DIR"
RUN_DIR="$APP_DIR/run"
LOG_DIR="$APP_DIR/logs"
mkdir -p "$RUN_DIR" "$LOG_DIR"

# ===== baked-in config (generated by deploy-backend.sh) =====
export NODE_ENV='__CFG_NODE_ENV__'
export STGY_FRONTEND_ORIGIN='__CFG_FRONTEND_ORIGIN__'
export STGY_BACKEND_PORT='__CFG_BACKEND_PORT__'
export STGY_BACKEND_API_BASE_URL='__CFG_BACKEND_API_BASE_URL__'
export STGY_BACKEND_API_PRIVATE_URL_LIST='__CFG_BACKEND_API_PRIVATE_URL_LIST__'
export PORT="${STGY_BACKEND_PORT}"

export STGY_DATABASE_HOST='__CFG_DB_HOST__'
export STGY_DATABASE_PORT='__CFG_DB_PORT__'
export STGY_DATABASE_USER='__CFG_DB_USER__'
export STGY_DATABASE_PASSWORD='__CFG_DB_PASS__'
export STGY_DATABASE_NAME='__CFG_DB_NAME__'

export STGY_STORAGE_DRIVER='s3'
export STGY_STORAGE_S3_ENDPOINT='__CFG_S3_ENDPOINT__'
export STGY_STORAGE_S3_REGION='__CFG_S3_REGION__'
export STGY_STORAGE_S3_ACCESS_KEY_ID='__CFG_S3_KEY__'
export STGY_STORAGE_S3_SECRET_ACCESS_KEY='__CFG_S3_SECRET__'
export STGY_STORAGE_S3_FORCE_PATH_STYLE='__CFG_S3_FORCE_PATH_STYLE__'
export STGY_STORAGE_S3_BUCKET_PREFIX='__CFG_S3_BUCKET_PREFIX__'
export STGY_STORAGE_S3_PUBLIC_URL_PREFIX='__CFG_S3_PUBLIC_URL_PREFIX__'

export STGY_REDIS_HOST='__CFG_REDIS_HOST__'
export STGY_REDIS_PORT='__CFG_REDIS_PORT__'
export STGY_REDIS_PASSWORD='__CFG_REDIS_PASS__'

export STGY_SMTP_HOST='__CFG_SMTP_HOST__'
export STGY_SMTP_PORT='__CFG_SMTP_PORT__'
export STGY_SMTP_USERNAME='__CFG_SMTP_USER__'
export STGY_SMTP_PASSWORD='__CFG_SMTP_PASS__'

export STGY_MAIL_SENDER_ADDRESS='__CFG_MAIL_FROM__'
export STGY_ID_ISSUE_WORKER_ID='__CFG_ID_WORKER__'
export STGY_OPENAI_API_KEY='__CFG_OPENAI_API_KEY__'
export STGY_TEST_SIGNUP_CODE='__CFG_TEST_SIGNUP_CODE__'
# ===========================================================

NODE_BIN="$(command -v node || true)"
if [[ -z "$NODE_BIN" ]]; then
  echo "[error] 'node' not found in PATH"
  exit 1
fi

pidfile() { echo "$RUN_DIR/$1.pid"; }
is_running() {
  local name="$1" pidfile_path; pidfile_path="$(pidfile "$name")"
  [[ -f "$pidfile_path" ]] || return 1
  local pid; pid="$(cat "$pidfile_path" 2>/dev/null || true)"
  [[ -n "$pid" && -d "/proc/$pid" ]] || return 1
  return 0
}

start_one() {
  local name="$1" entry="$2"
  local log="$LOG_DIR/$name.log" pf; pf="$(pidfile "$name")"
  if is_running "$name"; then
    echo "[$name] already running (pid $(cat "$pf"))"
    return 0
  fi
  echo "[$name] starting..."
  nohup "$NODE_BIN" "$entry" >>"$log" 2>&1 &
  echo $! >"$pf"
  sleep 0.2
  if is_running "$name"; then
    echo "[$name] started (pid $(cat "$pf"))"
  else
    echo "[$name] failed to start; see $log"
    return 1
  fi
}

stop_one() {
  local name="$1" pf; pf="$(pidfile "$name")"
  if ! is_running "$name"; then
    rm -f "$pf"
    echo "[$name] not running"
    return 0
  fi
  local pid; pid="$(cat "$pf")"
  echo "[$name] stopping (pid $pid)..."
  kill -TERM "$pid" 2>/dev/null || true

  # wait up to 10s, then KILL
  for _ in {1..20}; do
    if ! is_running "$name"; then
      break
    fi
    sleep 0.5
  done
  if is_running "$name"; then
    echo "[$name] still alive; killing..."
    kill -KILL "$pid" 2>/dev/null || true
  fi
  rm -f "$pf"
  echo "[$name] stopped"
}

status_one() {
  local name="$1" pf; pf="$(pidfile "$name")"
  if is_running "$name"; then
    echo "[$name] RUNNING (pid $(cat "$pf"))"
  else
    echo "[$name] STOPPED"
  fi
}

start_all() {
  start_one "backend" "dist/index.js"
  start_one "mailworker" "dist/mailWorker.js"
  start_one "mediaworker" "dist/mediaWorker.js"
  start_one "notificationworker" "dist/notificationWorker.js"
  start_one "aisummaryworker" "dist/aiSummaryWorker.js"
  start_one "aiuserworker" "dist/aiUserWorker.js"
}

stop_all() {
  # stop in reverse order to minimize dependency errors
  stop_one "aiuserworker"
  stop_one "aisummaryworker"
  stop_one "notificationworker"
  stop_one "mediaworker"
  stop_one "mailworker"
  stop_one "backend"
}

status_all() {
  status_one "backend"
  status_one "mailworker"
  status_one "mediaworker"
  status_one "notificationworker"
  status_one "aisummaryworker"
  status_one "aiuserworker"
}

# If launched without args: run in foreground & supervise children.
case "${1:-start}" in
  start)
    trap 'echo "[supervisor] SIGTERM received"; stop_all; exit 0' TERM INT
    start_all
    # Wait until any child exits; then stop the rest and propagate failure.
    while true; do
      if ! pgrep -F "$(pidfile backend)" >/dev/null 2>&1 || \
         ! pgrep -F "$(pidfile mailworker)" >/dev/null 2>&1 || \
         ! pgrep -F "$(pidfile mediaworker)" >/dev/null 2>&1 || \
         ! pgrep -F "$(pidfile notificationworker)" >/dev/null 2>&1 || \
         ! pgrep -F "$(pidfile aisummaryworker)" >/dev/null 2>&1 || \
         ! pgrep -F "$(pidfile aiuserworker)" >/dev/null 2>&1; then
        echo "[supervisor] a child process exited; stopping the others..."
        stop_all
        # non-zero exit if backend died
        exit 1
      fi
      sleep 1
    done
    ;;
  stop)
    stop_all
    ;;
  restart)
    stop_all
    start_all
    ;;
  status)
    status_all
    ;;
  *)
    echo "Usage: $0 [start|stop|restart|status]"
    exit 2
    ;;
esac
EOS

# Inject baked config values safely
sed -i \
  -e "s#__CFG_NODE_ENV__#${CFG_NODE_ENV}#g" \
  -e "s#__CFG_FRONTEND_ORIGIN__#${CFG_FRONTEND_ORIGIN}#g" \
  -e "s#__CFG_BACKEND_PORT__#${CFG_BACKEND_PORT}#g" \
  -e "s#__CFG_BACKEND_API_BASE_URL__#${CFG_BACKEND_API_BASE_URL}#g" \
  -e "s#__CFG_BACKEND_API_PRIVATE_URL_LIST__#${CFG_BACKEND_API_PRIVATE_URL_LIST}#g" \
  -e "s#__CFG_DB_HOST__#${CFG_DB_HOST}#g" \
  -e "s#__CFG_DB_PORT__#${CFG_DB_PORT}#g" \
  -e "s#__CFG_DB_USER__#${CFG_DB_USER}#g" \
  -e "s#__CFG_DB_PASS__#${CFG_DB_PASS}#g" \
  -e "s#__CFG_DB_NAME__#${CFG_DB_NAME}#g" \
  -e "s#__CFG_S3_ENDPOINT__#${CFG_S3_ENDPOINT}#g" \
  -e "s#__CFG_S3_REGION__#${CFG_S3_REGION}#g" \
  -e "s#__CFG_S3_KEY__#${CFG_S3_KEY}#g" \
  -e "s#__CFG_S3_SECRET__#${CFG_S3_SECRET}#g" \
  -e "s#__CFG_S3_FORCE_PATH_STYLE__#${CFG_S3_FORCE_PATH_STYLE}#g" \
  -e "s#__CFG_S3_BUCKET_PREFIX__#${CFG_S3_BUCKET_PREFIX}#g" \
  -e "s#__CFG_S3_PUBLIC_URL_PREFIX__#${CFG_S3_PUBLIC_URL_PREFIX}#g" \
  -e "s#__CFG_REDIS_HOST__#${CFG_REDIS_HOST}#g" \
  -e "s#__CFG_REDIS_PORT__#${CFG_REDIS_PORT}#g" \
  -e "s#__CFG_REDIS_PASS__#${CFG_REDIS_PASS}#g" \
  -e "s#__CFG_SMTP_HOST__#${CFG_SMTP_HOST}#g" \
  -e "s#__CFG_SMTP_PORT__#${CFG_SMTP_PORT}#g" \
  -e "s#__CFG_SMTP_USER__#${CFG_SMTP_USER}#g" \
  -e "s#__CFG_SMTP_PASS__#${CFG_SMTP_PASS}#g" \
  -e "s#__CFG_MAIL_FROM__#${CFG_MAIL_FROM}#g" \
  -e "s#__CFG_ID_WORKER__#${CFG_ID_WORKER}#g" \
  -e "s#__CFG_OPENAI_API_KEY__#${CFG_OPENAI_API_KEY}#g" \
  -e "s#__CFG_TEST_SIGNUP_CODE__#${CFG_TEST_SIGNUP_CODE}#g" \
  "$TARGET/start.sh"

chmod +x "$TARGET/start.sh"

# Ownership (best-effort if changing user/group)
if [[ "$(id -un)" != "$OWNER" ]] || [[ "$(id -gn)" != "$GROUP" ]]; then
  if command -v sudo >/dev/null 2>&1; then
    sudo chown -R "$OWNER:$GROUP" "$TARGET"
  else
    echo "[warn] Skipping chown (sudo not available): expected $OWNER:$GROUP -> $TARGET"
  fi
fi

echo "[backend] Deployment completed: $TARGET"
echo "  To run in foreground (recommended for systemd): $TARGET/start.sh"
echo "  To stop:                                         $TARGET/start.sh stop"
echo "  Logs: $TARGET/logs/*.log"
